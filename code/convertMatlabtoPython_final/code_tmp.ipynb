{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-06-26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No defined compartments in model model. Compartments will be deduced heuristically using regular expressions.\n",
      "Using regular expression found the following compartments:c, ce, e, er, erm, g, gm, lp, m, mm, n, p, v, vm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P -> [[0.46000001]] g/gDW\n",
      "X ->[[0.46000001]] gDW/DW\n",
      "Growth = 0.08158852335573963 1/h\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cobra\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from cobra.io import load_matlab_model, save_matlab_model, read_sbml_model, write_sbml_model\n",
    "import scipy.io as scio\n",
    "from scipy import sparse\n",
    "import cobra.util\n",
    "from cobra import Model,Reaction,Metabolite\n",
    "\n",
    "path = \"F:\\python\\Bayesian_python\"\n",
    "os.chdir(path)\n",
    "\n",
    "from code0824 import abc_python_max\n",
    "from code_generation_preparation import getrSample\n",
    "from code_generation_preparation import sumBiomass\n",
    "from code_generation_preparation import updateprior\n",
    "\n",
    "\n",
    "\n",
    "species = \"Saccharomyces_cerevisiae\"\n",
    "generation = 150\n",
    "enzymedataFile = \"data/Saccharomyces_cerevisiae_dl.mat\"\n",
    "#enzymedataFile = \"data/model.mat\"\n",
    "z = scio.loadmat(enzymedataFile)\n",
    "enzymedata = z['enzymedata'][0,0]\n",
    "max_growth = z['max_growth']\n",
    "growthdata = z['growthdata']\n",
    "model = z['model'][0,0]\n",
    "strain = z['strain']\n",
    "rxn2block = z['rxn2block']\n",
    "\n",
    "#load the model in cobra format\n",
    "scio.savemat('data/model.mat', {'model': model})\n",
    "model_cobra = load_matlab_model('data/model.mat')\n",
    "\n",
    "\n",
    "import scipy.io as io\n",
    "F = sumBiomass(model,model_cobra)\n",
    "#calculate the prot_weight\n",
    "#F = 0.46  #怎么从sumBiomass中导出结果，matlab版本为0.46\n",
    "tot_prot_weight = F[0]*0.5\n",
    "if strain == 'Kluyveromyces_marxianus':\n",
    "    tot_prot_weight = 0.325\n",
    "elif strain == 'Kluyveromyces_lactis':\n",
    "    tot_prot_weight = 0.245"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "    met = cobra.Metabolite ('cost' , name='cost' , compartment='c')\n",
    "    model_cobra.add_metabolites (met)\n",
    "    model_cobra.add_boundary (model_cobra.metabolites.get_by_id (\"cost\") , type=\"sink\" , ub=tot_prot_weight * 1000 , lb=0)\n",
    "    #nMets = len (model_cobra.metabolites)\n",
    "    nRxns = len (model_cobra.reactions)\n",
    "    cost_list = np.zeros ((nRxns , 1))\n",
    "    kcat_random = enzymedata['kcat']\n",
    "    prot_cost_info_value = [enzymedata[\"MW\"][i] / kcat_random[i] for i in range (len (kcat_random))]\n",
    "    prot_cost_info_value = [item[0] for item in prot_cost_info_value]\n",
    "    prot_cost_info_id = [str (item[0][0]) for item in enzymedata[\"rxn_list\"]]\n",
    "    prot_cost_info = dict (zip (prot_cost_info_id , prot_cost_info_value))\n",
    "    for p , rxnid in enumerate (model['rxns']):\n",
    "        rxnid = tuple (rxnid)\n",
    "        cost = prot_cost_info.get (rxnid[0][0] , 0)\n",
    "        cost_list[p , 0] = cost\n",
    "    cost_floats = [float (m) for m in cost_list]\n",
    "    for q , reaction in enumerate (model_cobra.reactions):\n",
    "        reaction.add_metabolites ({'cost': cost_floats[q]})\n",
    "\n",
    "    proc = 18\n",
    "    numPerGeneration = 126 #126/18 = 7\n",
    "    rejectnum = 0.2\n",
    "    generation = 100\n",
    "\n",
    "    if len(max_growth) == 0 and len(growthdata) == 0:\n",
    "        max_growth = [strain,'D-glucose',0.2,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,'aerobic','Batch','MIN']\n",
    "        simulated_3 = abc_python_max(model,enzymedata,enzymedata['kcat'],tot_prot_weight,growthdata,max_growth,1,1,1,rxn2block)\n",
    "        simulated_3_tmp = np.array(np.array(simulated_3)[2][0])[0,1]\n",
    "        if simulated_3_tmp >0.2:\n",
    "            max_growth = [strain,'D-glucose',simulated_3_tmp,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,'aerobic','Batch','MIN']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 3\u001B[0m D \u001B[38;5;241m=\u001B[39m \u001B[43mabc_python_max\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_cobra\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menzymedata\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menzymedata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mkcat\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtot_prot_weight\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrowthdata\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mmax_growth\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrxn2block\u001B[49m\u001B[43m,\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32mF:\\python\\Bayesian_python_ecmodel\\code0824.py:181\u001B[0m, in \u001B[0;36mabc_python_max\u001B[1;34m(model, model_cobra, enzymedata, kcat_random_all, tot_prot_weight, growthdata, max_growth, proc, sample_generation, j, rxn2block, num)\u001B[0m\n\u001B[0;32m    179\u001B[0m nstep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m (nstep)\n\u001B[0;32m    180\u001B[0m rmse_final \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros ((\u001B[38;5;241m1\u001B[39m , nstep))\n\u001B[1;32m--> 181\u001B[0m kcat_sample \u001B[38;5;241m=\u001B[39m \u001B[43mkcat_random_all\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m(\u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnstep\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;66;03m# get carbonnum for each exchange rxn to further calculation of error\u001B[39;00m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m (model[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexcarbon\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m==\u001B[39m\u001B[38;5;241m0\u001B[39m:  \u001B[38;5;66;03m##检查model中是否有excarbon, ~is_field\u001B[39;00m\n",
      "\u001B[1;31mIndexError\u001B[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "\n",
    "    output = 0\n",
    "\n",
    "    D = abc_python_max (model , model_cobra , enzymedata , enzymedata[\"kcat\"] , tot_prot_weight , growthdata ,\n",
    "                        max_growth , 1 , 1 , 1 , rxn2block,output)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 1finish !\n",
      "No. 2finish !\n",
      "No. 3finish !\n",
      "No. 4finish !\n",
      "No. 5finish !\n",
      "No. 6finish !\n",
      "No. 7finish !\n",
      "No. 8finish !\n",
      "No. 9finish !\n",
      "No. 10finish !\n",
      "No. 11finish !\n",
      "No. 12finish !\n",
      "No. 13finish !\n",
      "No. 14finish !\n",
      "No. 15finish !\n",
      "No. 16finish !\n",
      "No. 17finish !\n",
      "RMSE = 0.9819214215183005\n",
      "No. 1finish !\n",
      "No. 2finish !\n",
      "No. 3finish !\n",
      "No. 4finish !\n",
      "No. 5finish !\n",
      "No. 6finish !\n",
      "No. 7finish !\n",
      "No. 8finish !\n",
      "RMSE = 1.8940209096371767\n"
     ]
    }
   ],
   "source": [
    "        objective = 'r_2111'\n",
    "        osenseStr = 'max'\n",
    "        from code0824 import rmsecal\n",
    "        if len (growthdata)!=0:\n",
    "            rmse_1 , exp_1 , simulated_1 = rmsecal (model , model_cobra , growthdata , True , objective , osenseStr ,\n",
    "                                                    prot_cost_info_id , prot_cost_info_value ,prot_cost_info, tot_prot_weight ,\n",
    "                                                    rxn2block)\n",
    "        else:\n",
    "            rmse_1 = []\n",
    "            exp_1 = []\n",
    "            simulated_1 = []\n",
    "        # print(\"RMSE_1 finish !\")\n",
    "        # second searcch for maxmial growth rate without constrain\n",
    "        if len (max_growth)!=0:\n",
    "            rmse_2 , exp_2 , simulated_2 = rmsecal (model , model_cobra , max_growth , False , objective , osenseStr ,\n",
    "                                                    prot_cost_info_id , prot_cost_info_value ,prot_cost_info, tot_prot_weight ,\n",
    "                                                    rxn2block)\n",
    "        else:\n",
    "            rmse_2 = []\n",
    "            exp_2 = []\n",
    "            simulated_2 = []\n",
    "        #end_time = time.time ()\n",
    "        #execution_time = end_time - start_time\n",
    "        #print (\"execution time: \" , execution_time , \" seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_11288\\4076241837.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  exp = np.array ([exp_1 , exp_2])\n",
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_11288\\4076241837.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  simulated = np.array ([simulated_1 , simulated_2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.4379711655777387"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        exp = np.array ([exp_1 , exp_2])\n",
    "        simulated = np.array ([simulated_1 , simulated_2])\n",
    "        rmse = np.array ([rmse_1 , rmse_2])\n",
    "        rmse_final = np.nanmean (rmse , 0)\n",
    "        rmse_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "tmp = pd.read_csv('result/kcat_genra100.txt',delimiter=',',header=None)\n",
    "kcat_100 = np.array(tmp)\n",
    "kcat_100 = kcat_100[0:-2, :]\n",
    "[a, b] = updateprior(kcat_100)\n",
    "enzymedata['kcat'] = np.transpose(a)\n",
    "enzymedata['kcat_var'] = np.transpose(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "        if nfound > 0:\n",
    "            tmp = pd.read_csv('result/'+'kcat_genra' + str(output) + '.txt', delimiter=',',header= None)\n",
    "            tmp = np.array(tmp)\n",
    "            theta_100 = tmp[-1, :]\n",
    "            kcat_100 = tmp[0:-2, :]\n",
    "            tot_prot_weight = tmp[-2, 0]\n",
    "            sampledgeneration = output+1\n",
    "            # recalculate the sigma and mu\n",
    "            [a, b] = updateprior(kcat_100)\n",
    "            enzymedata['kcat'] = np.transpose(a)\n",
    "            enzymedata['kcat_var'] = np.transpose(b)\n",
    "        if sampledgeneration <= generation:\n",
    "            print(\"No. \" + str(output) + ' generation')\n",
    "\n",
    "            # generate a\n",
    "            old = theta_100\n",
    "            kcat_old_100 = kcat_100\n",
    "\n",
    "            # repeat a generation\n",
    "            if sampledgeneration == 1:\n",
    "                sample_generation = 144\n",
    "            else:\n",
    "                sample_generation = numPerGeneration\n",
    "\n",
    "            # generate one generation sample of kcats\n",
    "            kcat_random_all = getrSample(enzymedata['kcat'], enzymedata['kcat_var'], enzymedata['enzyme_ec_kcat_range'][:, 0],enzymedata['enzyme_ec_kcat_range'][:, 1], sample_generation,method = 'normal')\n",
    "            print(\"kcat random finish !\")\n",
    "            #print(kcat_random_all)\n",
    "            # start sampling\n",
    "            new_tmp = np.zeros((18, 7))\n",
    "            # Use a Pool to parallelize the work among 20 cores\n",
    "            num_cpus = 17\n",
    "            print(num_cpus)\n",
    "            with Pool (processes=num_cpus) as pool:\n",
    "                args = [(\n",
    "                        i , output , model , model_cobra , enzymedata , kcat_random_all , tot_prot_weight , growthdata ,\n",
    "                        max_growth , proc , sample_generation , rxn2block) for i in range (int (proc))]\n",
    "                results = pool.starmap (parallel_task , args)\n",
    "            new_tmp = np.vstack (results)\n",
    "            print(new_tmp)\n",
    "            print (\"RMSE calculation finish !\")\n",
    "\n",
    "            # find the best 100 samples\n",
    "            new = new_tmp\n",
    "            theta = np.append (old , new)\n",
    "            kcat = np.append (kcat_old_100 , kcat_random_all , axis=1)\n",
    "\n",
    "            # initialize an empty set to store the best 100 after each step\n",
    "            theta_100 = np.sort (theta.flatten ())[:100]\n",
    "            D = abs (theta_100[99] - theta_100[0])\n",
    "            D_idx = np.argsort (theta.flatten ())[:100]\n",
    "            D_100 = theta_100[99]\n",
    "            kcat_100 = kcat[: , D_idx]\n",
    "            tot = np.tile(tot_prot_weight, (1, len(theta_100)))\n",
    "            kcat_genra = []\n",
    "            for m in range(len(kcat_100[0,:])):\n",
    "                for n in range(len(tot[0,:])):\n",
    "                    if m == n:\n",
    "                        for k in range(len(theta_100)):\n",
    "                            if n == k:\n",
    "                                t = np.append(kcat_100[:,m], tot[:,n])\n",
    "                                t = np.append(t, theta_100[k])\n",
    "                                kcat_genra.append(t)\n",
    "            kcat_genra = np.transpose (kcat_genra)\n",
    "            path = 'result'\n",
    "            os.makedirs (path , exist_ok=True)\n",
    "            filename = 'kcat_genra' + str (output+1) + '.txt'\n",
    "            full_path = os.path.join (path , filename)\n",
    "            np.savetxt (full_path , kcat_genra,delimiter=\",\", fmt=\"%f\")\n",
    "\n",
    "            # recalclate the sigma and mu\n",
    "            [a , b] = updateprior (kcat_100)\n",
    "            enzymedata['kcat'] = np.transpose(a)\n",
    "            enzymedata['kcat_var'] = np.transpose(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read LP format model from file C:\\Users\\sherr\\AppData\\Local\\Temp\\tmpj6t2h641.lp\n",
      "Reading time = 0.04 seconds\n",
      ": 2743 rows, 12418 columns, 48160 nonzeros\n"
     ]
    }
   ],
   "source": [
    "model1 = read_sbml_model(\"ecYeastGEM.xml\")\n",
    "model2 = read_sbml_model(\"ecYeast_DL_update_some_kcat.xml\")\n",
    "model3 = read_sbml_model(\"scer_test_model.xml\")\n",
    "model4 = model_cobra.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metabolites1 = set([m.id for m in ecModel.metabolites])\n",
    "metabolites2 = set([m.id for m in model_cobra.metabolites])\n",
    "reactions1 = set([r.id for r in ecModel.reactions])\n",
    "reactions2 = set([r.id for r in model_cobra.reactions])\n",
    "\n",
    "# 找出只在一个模型中存在的代谢物和反应\n",
    "unique_metabolites1 = metabolites1 - metabolites2\n",
    "unique_metabolites2 = metabolites2 - metabolites1\n",
    "unique_reactions1 = reactions1 - reactions2\n",
    "unique_reactions2 = reactions2 - reactions1\n",
    "\n",
    "# 输出结果\n",
    "print(\"Unique metabolites in model1:\", unique_metabolites1)\n",
    "print(\"Unique metabolites in model2:\", unique_metabolites2)\n",
    "print(\"Unique reactions in model1:\", unique_reactions1)\n",
    "print(\"Unique reactions in model2:\", unique_reactions2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "#原版代码\n",
    "\n",
    "def constrainAbandance(model,measured):\n",
    "    '''\n",
    "    model       : eModel from convertToEnzymeModel()\n",
    "    measured    : a dictionary with measured enzyme abandance, in the unit of mmol/gdw\n",
    "    g\n",
    "    # define the upper bound of protein exchange reactions with protein abandance.\n",
    "    # e.g. the reaction id is in the format of \"prot_TD01GL001367_exchange\"\n",
    "\n",
    "    Usage: model = constrainAbandance(model,MWs, non_measured,UB)\n",
    "    '''\n",
    "\n",
    "    for prot_id, ab in measured.items():\n",
    "        rxn_id = 'prot_{0}_exchange'.format(prot_id)\n",
    "        model.reactions.get_by_id(rxn_id).upper_bound = ab\n",
    "\n",
    "    return model\n",
    "\n",
    "def constrainPool(model,MWs, measured, non_measured,UB,copy=True):\n",
    "    '''\n",
    "\n",
    "    model       : eModel from convertToEnzymeModel()\n",
    "    MWs         : a dictionary with molecular weight of enzymes, in the unit of kDa\n",
    "    non_measured: a list of enzymes without proteomics data\n",
    "    measured    : a dictionary with measured enzyme abandance, in the unit of mmol/gdw\n",
    "    UB          : upper bound for the combined pool of those non_measured enzymes\n",
    "    copy        : if creat a copy of the original model\n",
    "\n",
    "    Define new rxns: For each enzyme, add a new rxn that draws enzyme from the\n",
    "    enzyme pool (a new metabolite), and remove previous exchange rxn. The new\n",
    "    rxns have the following stoichiometry (T is the enzyme pool):\n",
    "     MW[i]*P[T] -> P[i]\n",
    "\n",
    "    Usage: model = constrainPool(model,MWs, non_measured,UB)\n",
    "\n",
    "    Gang Li, last updated 2020-03-04\n",
    "    '''\n",
    "    if copy: model = model.copy()\n",
    "    # create prot_pool metabolite\n",
    "    prot_pool = Metabolite('prot_pool')\n",
    "    prot_pool.name = prot_pool.id\n",
    "\n",
    "    rxns_to_add  = list()\n",
    "    rxns_to_drop = list()\n",
    "    for prot in non_measured:\n",
    "        #prot_exchange_rxn = model.reactions.get_by_id('prot_{0}_exchange'.format(prot))\n",
    "        prot_exchange_rxn = model.reactions.get_by_id('prot_{0}'.format(prot[0]))\n",
    "\n",
    "        draw_rxn = Reaction('draw_prot_{0}'.format(prot))\n",
    "        draw_rxn.name = draw_rxn.id\n",
    "        draw_rxn.add_metabolites({prot_pool:-MWs[prot],list(prot_exchange_rxn.metabolites)[0]:1})\n",
    "\n",
    "        rxns_to_add.append(draw_rxn)\n",
    "        rxns_to_drop.append(prot_exchange_rxn)\n",
    "\n",
    "    # add draw reaction into model\n",
    "    model.add_reactions(rxns_to_add)\n",
    "    model.remove_reactions(rxns_to_drop)\n",
    "\n",
    "    # change the upper bound for all reactions as np.inf\n",
    "    for rxn in model.reactions: rxn.upper_bound = np.inf\n",
    "\n",
    "    # add prot_pool_exchange rxn\n",
    "    rxn_prot_pool_exg = Reaction('prot_pool_exchange')\n",
    "    rxn_prot_pool_exg.name = rxn_prot_pool_exg.id\n",
    "    rxn_prot_pool_exg.add_metabolites({prot_pool:1})\n",
    "    rxn_prot_pool_exg.lower_bound = 0\n",
    "    rxn_prot_pool_exg.upper_bound = UB\n",
    "\n",
    "    model.add_reaction(rxn_prot_pool_exg)\n",
    "\n",
    "    # constrain the proteins with measure abandance\n",
    "    constrainAbandance(model,measured)\n",
    "\n",
    "    return model\n",
    "\n",
    "def addEnzymesToRxn(rxn, kcat, protIDs, rxn_index=None):\n",
    "    '''\n",
    "    Add each enzyme as one of metabolites in the model, Current version does not support stoichiometric cofficients of subunits\n",
    "    rxn      : the input Reaction object in cobrapy\n",
    "    rxn_index: a integer like 1, for isoenzymes\n",
    "    kcats    : kcat value for the reaction\n",
    "    protIDs  : a single protein name, like \"A\", or a complex like \"A and B\". String\n",
    "    MWs      : a dictionary with prot_id as key and molecular weight as value\n",
    "\n",
    "    Usage: e_rxn, prot_exchange_rxns = addEnzymesToRxn(rxn, kcat, protIDs,MWs)\n",
    "\n",
    "    Gang Li, last updated 2020-03-03\n",
    "    '''\n",
    "\n",
    "    e_rxn      = rxn.copy()\n",
    "    if rxn_index is not None:\n",
    "        e_rxn.id   = e_rxn.id + 'No{0}'.format(rxn_index)\n",
    "        e_rxn.name = e_rxn.name + ' (No{0})'.format(rxn_index)\n",
    "    prots = [item.strip() for item in protIDs.split('and')]\n",
    "\n",
    "\n",
    "    # get compartment\n",
    "    comp = None\n",
    "    for met in rxn.metabolites:\n",
    "        comp = met.compartment\n",
    "        if rxn.get_coefficient(met)<0: comp = met.compartment\n",
    "\n",
    "    # create Metabolite object for each protein and create exchange reaction\n",
    "    prot_mets = []\n",
    "    prot_exchange_rxns = []\n",
    "    for prot in prots:\n",
    "        prot_met = Metabolite('prot_{0}[{1}]'.format(prot,comp))\n",
    "        prot_met.compartment =  comp\n",
    "        prot_mets.append(prot_met)\n",
    "\n",
    "        # add excange reaction of protein\n",
    "        excg_rxn = Reaction('prot_{0}_exchange'.format(prot))\n",
    "        excg_rxn.lower_bound = 0\n",
    "        excg_rxn.gene_reaction_rule = prot\n",
    "        excg_rxn.add_metabolites({prot_met:1})\n",
    "        prot_exchange_rxns.append(excg_rxn)\n",
    "\n",
    "    # add enzymes into reaction\n",
    "    e_rxn.add_metabolites({prot_met:-1./kcat for prot_met in prot_mets})\n",
    "    e_rxn.gene_reaction_rule = protIDs\n",
    "\n",
    "    return e_rxn, prot_exchange_rxns\n",
    "\n",
    "def convertToEnzymeModel(model,kcats):\n",
    "    '''\n",
    "    model .   : irrevModel\n",
    "    kcats     : a dictionary with kcat values {('protein_id',rxn_id):100,...}\n",
    "\n",
    "    Usage: eModel = convertToEnzymeModel(model,kcats)\n",
    "\n",
    "    Gang Li, last updated 2020-03-04\n",
    "    '''\n",
    "    converted_reaction_list = []\n",
    "    protein_exchange_rxns = {}\n",
    "    for rxn in model.reactions:\n",
    "        complexes = parse_gr_rule(rxn.gene_reaction_rule)\n",
    "\n",
    "        # 1. for those reactions without genes\n",
    "        if len(complexes) <1:\n",
    "            converted_reaction_list.append(rxn)\n",
    "            continue\n",
    "\n",
    "        # 2. for those reactions with genes, but no kcat\n",
    "        first_gene = [gene.id for gene in rxn.genes][0]\n",
    "        if kcats.get((first_gene,rxn.id),None) is None:\n",
    "            converted_reaction_list.append(rxn)\n",
    "            continue\n",
    "\n",
    "        # 3. for those reactions with isoenzymes, add arm reaction\n",
    "        if len(complexes) >1:\n",
    "            rxn_new, arm_rxn = getArmReaction(rxn)\n",
    "            converted_reaction_list.append(arm_rxn)\n",
    "\n",
    "            for i,complx in enumerate(complexes):\n",
    "                prots = [item.strip() for item in complx.split('and')]\n",
    "                kcat = kcats[(prots[0],rxn.id)]\n",
    "                e_rxn, prot_exchange_rxns = addEnzymesToRxn(rxn_new, kcat, complx,rxn_index=i+1)\n",
    "\n",
    "                converted_reaction_list.append(e_rxn)\n",
    "                for prot_exchange_rxn in prot_exchange_rxns: protein_exchange_rxns[prot_exchange_rxn.id] = prot_exchange_rxn\n",
    "\n",
    "            continue\n",
    "\n",
    "        if len(complexes) == 1:\n",
    "            complx = complexes[0]\n",
    "            prots = [item.strip() for item in complx.split('and')]\n",
    "            kcat = kcats[(prots[0],rxn.id)]\n",
    "            e_rxn, prot_exchange_rxns = addEnzymesToRxn(rxn, kcat, complx,rxn_index=1)\n",
    "            converted_reaction_list.append(e_rxn)\n",
    "            for prot_exchange_rxn in prot_exchange_rxns: protein_exchange_rxns[prot_exchange_rxn.id] = prot_exchange_rxn\n",
    "\n",
    "    eModel = Model()\n",
    "    eModel.add_reactions(converted_reaction_list)\n",
    "    eModel.add_reactions(protein_exchange_rxns.values())\n",
    "    eModel.enzymes = set([exgrxn.split('_')[1] for exgrxn in protein_exchange_rxns.keys()])\n",
    "    print('Number of enzymes:', len(eModel.enzymes))\n",
    "\n",
    "    return eModel\n",
    "\n",
    "def getArmReaction(rxn):\n",
    "    '''\n",
    "    Adapted from addArmReaction.m from geckomat. Add an arm reaction for the selected reaction in the model.\n",
    "\n",
    "    rxn: the reaction Object in cobrapy\n",
    "\n",
    "    Original reaction: A + B --> C + D\n",
    "\n",
    "    Arm reaction    : A + B --> pmet   (no gr rule)\n",
    "    Change the orginial reaction to:  pmet --> C + D (use old gr rule)\n",
    "\n",
    "    The arm reaction has a id format of \"arm_rxnID\" and a name format of \"rxnName (arm)\"\n",
    "\n",
    "    The intermediate metabilite has a name format of \"pmet_rxnID\"\n",
    "\n",
    "    The arm reaction shares the same lb, ub, gr rules, subsystems with original reaction.\n",
    "\n",
    "    Compartment: fistly try to use the same compartment as substrates, then products', otherwise None.\n",
    "\n",
    "\n",
    "    Usage: rxn_new, arm_rxn = addArmReaction(model,rxn_id).\n",
    "\n",
    "    Gang Li, Last update: 2020-03-03\n",
    "    '''\n",
    "\n",
    "    # 1. create intermediate metabilite\n",
    "    rxnID = rxn.id\n",
    "    comp = None\n",
    "    for met in rxn.metabolites:\n",
    "        comp = met.compartment\n",
    "        if rxn.get_coefficient(met)<0: comp = met.compartment\n",
    "\n",
    "    pmet = Metabolite('pmet_{0}'.format(rxnID),compartment=comp)\n",
    "\n",
    "    # 2. create arm reaction:\n",
    "    arm_rxn                    = Reaction('arm_{0}'.format(rxnID))\n",
    "    arm_rxn.name               = rxn.name + ' (arm)'\n",
    "    arm_rxn.subsystem          = rxn.subsystem\n",
    "    arm_rxn.lower_bound        = rxn.lower_bound\n",
    "    arm_rxn.upper_bound        = rxn.upper_bound\n",
    "    arm_rxn.gene_reaction_rule = ''\n",
    "\n",
    "    mets = {met:rxn.get_coefficient(met) for met in rxn.metabolites if rxn.get_coefficient(met)<0}\n",
    "    mets[pmet] = 1\n",
    "\n",
    "    arm_rxn.add_metabolites(mets)\n",
    "\n",
    "    # 3. change orignal reaction to pmet --> C + D\n",
    "    rxn_new = rxn.copy()\n",
    "    rxn_new.subtract_metabolites({met:rxn_new.get_coefficient(met) for met in rxn_new.metabolites if rxn_new.get_coefficient(met)<0})\n",
    "    rxn_new.add_metabolites({pmet:-1})\n",
    "\n",
    "    return rxn_new, arm_rxn\n",
    "\n",
    "def parse_gr_rule(gr):\n",
    "    '''\n",
    "    Parse gr rule into a list of components.\n",
    "    gr: gene reaction rule, defined in cobrapy.\n",
    "\n",
    "    For example:\n",
    "\n",
    "    Input         : Output\n",
    "    A or B        : [\"A\", \"B\"]\n",
    "    (A and B)     : [\"A and B\"]\n",
    "    (A and B) or C: [\"A and B\",\"C\"]\n",
    "\n",
    "    Usage: complexes = parse_gr_rule(gr)\n",
    "\n",
    "    Gang Li, last updated 2020-03-04\n",
    "\n",
    "    '''\n",
    "    complexes = [item.strip().replace('(','').replace(')','') for item in gr.split('or')]\n",
    "    if len(complexes) < 2 and len(complexes[0]) < 1: complexes = []\n",
    "\n",
    "    return complexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'proteins'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [140]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#enzymedataFile = \"data/model.mat\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m ecpost \u001B[38;5;241m=\u001B[39m scio\u001B[38;5;241m.\u001B[39mloadmat(ecpost)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mecpost\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mproteins\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'proteins'"
     ]
    }
   ],
   "source": [
    "ecpost = \"emodel_Saccharomyces_cerevisiae_Posterior_mean.mat\"\n",
    "#enzymedataFile = \"data/model.mat\"\n",
    "ecpost = scio.loadmat(ecpost)\n",
    "ecpost['proteins']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "41 columns passed, passed data had 100 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:982\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[1;34m(content, columns, dtype)\u001B[0m\n\u001B[0;32m    981\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 982\u001B[0m     columns \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_or_indexify_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    984\u001B[0m     \u001B[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:1030\u001B[0m, in \u001B[0;36m_validate_or_indexify_columns\u001B[1;34m(content, columns)\u001B[0m\n\u001B[0;32m   1028\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_mi_list \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(columns) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(content):  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[0;32m   1029\u001B[0m     \u001B[38;5;66;03m# caller's responsibility to check for this...\u001B[39;00m\n\u001B[1;32m-> 1030\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m   1031\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(columns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m columns passed, passed data had \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1032\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(content)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m columns\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1033\u001B[0m     )\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_mi_list:\n\u001B[0;32m   1035\u001B[0m \n\u001B[0;32m   1036\u001B[0m     \u001B[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001B[39;00m\n",
      "\u001B[1;31mAssertionError\u001B[0m: 41 columns passed, passed data had 100 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [157]\u001B[0m, in \u001B[0;36m<cell line: 23>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m     last_lines\u001B[38;5;241m.\u001B[39mappend(last_line_values)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Convert the list of last lines into a DataFrame\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlast_lines\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumn_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;66;03m# Save the DataFrame to an Excel file\u001B[39;00m\n\u001B[0;32m     26\u001B[0m excel_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlast_lines_kcat_genra.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:721\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    716\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    717\u001B[0m         \u001B[38;5;66;03m# error: Argument 1 to \"ensure_index\" has incompatible type\u001B[39;00m\n\u001B[0;32m    718\u001B[0m         \u001B[38;5;66;03m# \"Collection[Any]\"; expected \"Union[Union[Union[ExtensionArray,\u001B[39;00m\n\u001B[0;32m    719\u001B[0m         \u001B[38;5;66;03m# ndarray], Index, Series], Sequence[Any]]\"\u001B[39;00m\n\u001B[0;32m    720\u001B[0m         columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m--> 721\u001B[0m     arrays, columns, index \u001B[38;5;241m=\u001B[39m \u001B[43mnested_data_to_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001B[39;49;00m\n\u001B[0;32m    723\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001B[39;49;00m\n\u001B[0;32m    724\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    725\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    726\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m    727\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    728\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    729\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[0;32m    730\u001B[0m         arrays,\n\u001B[0;32m    731\u001B[0m         columns,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    734\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    735\u001B[0m     )\n\u001B[0;32m    736\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:519\u001B[0m, in \u001B[0;36mnested_data_to_arrays\u001B[1;34m(data, columns, index, dtype)\u001B[0m\n\u001B[0;32m    516\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_named_tuple(data[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;129;01mand\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    517\u001B[0m     columns \u001B[38;5;241m=\u001B[39m ensure_index(data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fields)\n\u001B[1;32m--> 519\u001B[0m arrays, columns \u001B[38;5;241m=\u001B[39m \u001B[43mto_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    520\u001B[0m columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[0;32m    522\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:883\u001B[0m, in \u001B[0;36mto_arrays\u001B[1;34m(data, columns, dtype)\u001B[0m\n\u001B[0;32m    880\u001B[0m     data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtuple\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[0;32m    881\u001B[0m     arr \u001B[38;5;241m=\u001B[39m _list_to_arrays(data)\n\u001B[1;32m--> 883\u001B[0m content, columns \u001B[38;5;241m=\u001B[39m \u001B[43m_finalize_columns_and_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m content, columns\n",
      "File \u001B[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py:985\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[1;34m(content, columns, dtype)\u001B[0m\n\u001B[0;32m    982\u001B[0m     columns \u001B[38;5;241m=\u001B[39m _validate_or_indexify_columns(contents, columns)\n\u001B[0;32m    983\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    984\u001B[0m     \u001B[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n\u001B[1;32m--> 985\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    987\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(contents) \u001B[38;5;129;01mand\u001B[39;00m contents[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mobject_:\n\u001B[0;32m    988\u001B[0m     contents \u001B[38;5;241m=\u001B[39m _convert_object_array(contents, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[1;31mValueError\u001B[0m: 41 columns passed, passed data had 100 columns"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create a list to store the last lines of each file\n",
    "last_lines = []\n",
    "column_names = []\n",
    "\n",
    "# Iterate through all the kcat_genra*.txt files\n",
    "for i in range(1, 42):  # Assuming the files are numbered from 1 to 40\n",
    "    file_name = f\"result/kcat_genra{i}.txt\"\n",
    "    column_names.append(str(i))\n",
    "\n",
    "    # Read the last line of each file\n",
    "    with open(file_name, 'r') as file:\n",
    "        last_line = file.readlines()[-1]\n",
    "\n",
    "    # Convert the last line to a list of values\n",
    "    last_line_values = last_line.strip().split(',')\n",
    "\n",
    "    last_lines.append(last_line_values)\n",
    "\n",
    "# Convert the list of last lines into a DataFrame\n",
    "df = pd.DataFrame(last_lines, columns=column_names)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_path = 'last_lines_kcat_genra.xlsx'\n",
    "df.to_excel(excel_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame to store the last lines\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Iterate through all the kcat_genra*.txt files\n",
    "for i in range(1, 41):  # Assuming the files are numbered from 1 to 40\n",
    "    file_name = f\"result/kcat_genra{i}.txt\"\n",
    "\n",
    "    # Read the last line of each file\n",
    "    with open(file_name, 'r') as file:\n",
    "        last_line = file.readlines()[-1]\n",
    "\n",
    "    # Convert the last line to a list of floating-point numbers\n",
    "    last_line_values = [float(x) for x in last_line.strip().split(',')]\n",
    "\n",
    "    # Add the last line values to the DataFrame as a new column\n",
    "    df[f\"{i}\"] = last_line_values\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_path = 'last_lines_kcat_genra.xlsx'\n",
    "df.to_excel(excel_path, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nstep:1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 1finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 2finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 3finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 4finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 5finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 6finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 7finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 8finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 9finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 10finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 11finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 12finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 13finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 14finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 15finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 16finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 17finish !\n",
      "RMSE = 8.05523093429684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 1finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 2finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 3finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 4finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 5finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 6finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 7finish !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  exp = exp.astype (np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 8finish !\n",
      "RMSE = 4.166851739822311\n",
      "execution time:  52.10885310173035  seconds\n",
      "rmse_final is  [[6.11104134]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:180: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  exp = np.array ([exp_1 , exp_2])\n",
      "C:\\Users\\sherr\\AppData\\Local\\Temp\\ipykernel_2776\\423083270.py:181: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  simulated = np.array ([simulated_1 , simulated_2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[6.11104134]]),\n array([array([[ 2.50000000e-02, -3.00000000e-01,  0.00000000e+00,\n                 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  7.51980000e-01, -7.31020000e-01],\n               [ 5.00000000e-02, -6.00000000e-01,  0.00000000e+00,\n                 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  1.36970000e+00, -1.32510000e+00],\n               [ 1.00000000e-01, -1.10000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  2.40070000e+00, -2.31670000e+00],\n               [ 1.50000000e-01, -1.70000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  3.63790000e+00, -3.50660000e+00],\n               [ 2.00000000e-01, -2.30000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  4.87510000e+00, -4.69660000e+00],\n               [ 2.50000000e-01, -2.80000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  5.90600000e+00, -5.68810000e+00],\n               [ 2.80000000e-01, -3.40000000e+00,  8.00000000e-02,\n                 1.10000000e-01,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  7.04130000e+00, -6.67730000e+00],\n               [ 3.00000000e-01, -4.50000000e+00,  4.10000000e-01,\n                 2.30000000e+00,  0.00000000e+00,  0.00000000e+00,\n                 0.00000000e+00,  8.56670000e+00, -6.01200000e+00],\n               [ 3.50000000e-01, -8.60000000e+00,  6.20000000e-01,\n                 9.50000000e+00,  5.00000000e-02,  0.00000000e+00,\n                 0.00000000e+00,  1.52091000e+01, -5.38090000e+00],\n               [ 4.00000000e-01, -1.11000000e+01,  6.00000000e-01,\n                 1.39000000e+01,  1.50000000e-01,  0.00000000e+00,\n                 0.00000000e+00,  1.93207000e+01, -5.01710000e+00],\n               [ 1.00000000e-01, -5.77159911e+00,  0.00000000e+00,\n                 9.52813144e+00,  7.03426334e-01,  0.00000000e+00,\n                 0.00000000e+00,  9.91000000e+00,  0.00000000e+00],\n               [ 2.00000000e-01, -1.19448835e+01,  0.00000000e+00,\n                 1.82168000e+01,  1.65020000e+00,  0.00000000e+00,\n                 0.00000000e+00,  1.91900000e+01,  0.00000000e+00],\n               [ 3.00000000e-01, -1.73800000e+01,  0.00000000e+00,\n                 2.74696000e+01,  2.67430000e+00,  0.00000000e+00,\n                 0.00000000e+00,  2.90500000e+01,  0.00000000e+00],\n               [ 4.00000000e-01, -2.36540827e+01,  0.00000000e+00,\n                 3.72195000e+01,  3.84830000e+00,  0.00000000e+00,\n                 0.00000000e+00,  3.95200000e+01,  0.00000000e+00],\n               [ 4.10000000e-01, -1.42222222e+01,             nan,\n                 2.56250000e+01,  4.60000000e-01,  0.00000000e+00,\n                 0.00000000e+00,             nan,             nan],\n               [ 2.50000000e-01, -1.24444444e+01,             nan,\n                 2.02569170e+01,  4.10000000e-01,  0.00000000e+00,\n                 0.00000000e+00,             nan,  0.00000000e+00],\n               [ 3.20000000e-01, -6.07654105e+00,             nan,\n                 1.99420290e+01,             nan,  0.00000000e+00,\n                 0.00000000e+00,             nan,  0.00000000e+00]]),\n        array([[0.338,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.28 ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.41 ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.33 ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.17 ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.12 ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.4  ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan],\n               [0.39 ,   nan,   nan,   nan,   nan, 0.   , 0.   ,   nan,   nan]])],\n       dtype=object),\n array([array([[  0.02231465,  -0.3       ,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   0.83812283,\n                 -0.80082475],\n               [  0.04771777,  -0.6       ,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   1.5431165 ,\n                 -1.46335809],\n               [  0.09005627,  -1.1       ,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   2.71810582,\n                 -2.56758013],\n               [  0.14086237,  -1.7       ,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.12809179,\n                 -3.89264435],\n               [  0.16318914,  -1.96728375,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914143,\n                 -4.4963703 ],\n               [  0.16318914,  -1.96728375,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914143,\n                 -4.4963703 ],\n               [  0.16318914,  -1.96728375,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914143,\n                 -4.4963703 ],\n               [  0.16318914,  -1.96728375,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914143,\n                 -4.4963703 ],\n               [  0.16318914,  -1.96728375,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914143,\n                 -4.4963703 ],\n               [  0.16318914,  -1.96728375,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914143,\n                 -4.4963703 ],\n               [  0.11016346,  -5.77159911,   0.        ,  10.12068933,\n                  0.        ,   0.        ,   0.        ,  10.20224827,\n                  0.        ],\n               [  0.14346344,  -8.41712238,   0.        ,  13.18048783,\n                  1.54316711,   0.        ,   0.        ,  14.06096433,\n                  0.        ],\n               [  0.14346344,  -8.41712238,   0.        ,  13.18048783,\n                  1.54316711,   0.        ,   0.        ,  14.06096433,\n                  0.        ],\n               [  0.14346344,  -8.41712238,   0.        ,  13.18048783,\n                  1.54316711,   0.        ,   0.        ,  14.06096433,\n                  0.        ],\n               [  0.16318936,  -1.96728637,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914761,\n                 -4.49637611],\n               [  0.22716248, -12.44444444,   0.        ,  21.28808606,\n                  0.5709472 ,   0.        ,   0.        ,  21.74598225,\n                  0.        ],\n               [  0.19021592,  -6.07654105,   0.        ,  17.47580147,\n                  2.046061  ,   0.        ,   0.        ,  18.64321142,\n                  0.        ]])                                        ,\n        array([[  0.23647774, -11.46504319,   0.        ,  18.77711397,\n                  0.        ,   0.        ,   0.        ,  21.04223368,\n                 -1.74041572],\n               [  0.15677851,  -1.99913636,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   5.23659899,\n                 -4.97454326],\n               [  0.16318936,  -1.96728637,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.76914761,\n                 -4.49637611],\n               [  0.16471412,  -4.6191512 ,   0.        ,   5.06725322,\n                  0.        ,   0.        ,   0.        ,  10.48010284,\n                 -5.1375295 ],\n               [  0.07421065,  -4.26902826,  -4.26902826,   0.        ,\n                  0.        ,   0.        ,   0.        ,   5.33919305,\n                 -5.21514268],\n               [  0.09837215,  -3.4558921 ,   0.        ,  -3.4558921 ,\n                  0.        ,   0.        ,   0.        ,   2.67143499,\n                 -5.9628884 ],\n               [  0.15802037,  -0.96141317,   0.        ,   0.        ,\n                  0.        ,   0.        ,   0.        ,   4.72520631,\n                 -4.46107481],\n               [  0.2364189 , -11.46227765,   0.        ,  18.77261618,\n                  0.        ,   0.        ,   0.        ,  21.03717231,\n                 -1.73998269]])                                        ],\n       dtype=object))"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = \"Saccharomyces_cerevisiae\"\n",
    "generation = 150\n",
    "enzymedataFile = \"data/emodel_Saccharomyces_cerevisiae_dl.mat\"\n",
    "#enzymedataFile = \"data/model.mat\"\n",
    "zz = scio.loadmat(enzymedataFile)\n",
    "\n",
    "emodel = zz['emodel'][0,0]\n",
    "\n",
    "\n",
    "#load the model in cobra format\n",
    "#scio.savemat('data/emodel.mat', {'emodel': emodel})\n",
    "#model_cobra2 = load_matlab_model('data/emodel.mat')\n",
    "model_cobra2 = read_sbml_model('data/emodel_Saccharomyces_cerevisiae_DL.xml')\n",
    "output = 0\n",
    "D = abc_python_max (model , model_cobra2 , enzymedata , enzymedata[\"kcat\"] , tot_prot_weight , growthdata ,\n",
    "                        max_growth , 1 , 1 , 1 , rxn2block,1)\n",
    "D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cobra\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from cobra.io import load_matlab_model , save_matlab_model , read_sbml_model , write_sbml_model\n",
    "import scipy.io as scio\n",
    "from scipy import sparse\n",
    "import cobra.util\n",
    "from cobra import Model , Reaction , Metabolite\n",
    "import cProfile\n",
    "import time\n",
    "from multiprocessing import cpu_count , Manager , Process\n",
    "from code_generation_preparation import changeMedia\n",
    "from code_generation_preparation import anaerobicModel\n",
    "\n",
    "def rmsecal(model , model_cobra , data , constrain , objective , osenseStr , prot_cost_info_id , prot_cost_info_value ,prot_cost_info,\n",
    "            tot_prot_weight , rxn2block):\n",
    "    data = np.array (data)\n",
    "    rmse_tmp = []\n",
    "    simulated = np.zeros ((len (data[: , 0]) , 9))\n",
    "    rxnNames = model['rxnNames']\n",
    "    for i in range (len (data[: , 0])):\n",
    "        exp = np.array (data[: , 2:11])  # u sub ace eth gly pyr ethyl_acetate co2 o2\n",
    "        exp = exp * [1 , -1 , 1 , 1 , 1 , 1 , 1 , 1 , -1]\n",
    "        exp = exp.astype (np.float)\n",
    "        ex_mets = ['growth' , data[i , 1][0] + \" exchange\" , 'acetate exchange' , 'ethanol exchange' ,\n",
    "                   'glycerol exchange' , 'pyruvate exchange' , 'ethyl acetate exchange' , 'carbon dioxide exchange' ,\n",
    "                   'oxygen exchange']\n",
    "        idx = []\n",
    "        temp = []\n",
    "        for k in range (len (ex_mets)):\n",
    "            temp = np.where (rxnNames==ex_mets[k])\n",
    "            idx.append (temp)\n",
    "        idx = np.array (idx)\n",
    "        idx = np.transpose (idx[: , 0])\n",
    "        # Create a temp model\n",
    "        start_time1 = time.time ()\n",
    "\n",
    "        with model_cobra as model_tmp:\n",
    "\n",
    "            # Suitable for different carbon sources\n",
    "            #model_tmp = changeMedia (model , model_tmp , data[i , 1][0] , data[i , 15])  # 'D-glucose'\n",
    "            model_tmp = changeMedia (model , model_tmp , 'D-glucose' , data[i , 15])\n",
    "            model_tmp.reactions.get_by_id ('r_1634').bounds = 0 , 0\n",
    "            model_tmp.reactions.get_by_id ('r_1631').bounds = 0 , 0\n",
    "\n",
    "            # Suitable for anaerobic\n",
    "            if data[i , 13]==\"anaerobic\" or data[i , 13]==\"limited\":\n",
    "                model_tmp = anaerobicModel (model , model_tmp)\n",
    "\n",
    "            if data[i , 13]==\"limited\":\n",
    "                model_tmp.reactions.get_by_any ('oxygen exchange').lower_bound = -5\n",
    "\n",
    "            model_tmp.reactions.get_by_id ('r_1714').lower_bound = 0\n",
    "\n",
    "            id_substrate = np.where (model['rxnNames']==(data[i , 1][0] + \" exchange\"))\n",
    "            if constrain==False:\n",
    "                model_tmp.reactions[idx[0][1]].lower_bound = -1000\n",
    "            else:\n",
    "                model_tmp.reactions[idx[0][1]].lower_bound = exp[i , 1]\n",
    "\n",
    "\n",
    "            # Solve the temp model\n",
    "            sol_tmp = model_tmp.optimize ()\n",
    "            sol = sol_tmp.fluxes  # sol[:,i] = sol_tmp.fluxes\n",
    "\n",
    "        print (\"No. \" + str (i + 1) + \"finish !\")\n",
    "\n",
    "        tmp = np.where (~np.isnan (exp[i]))[0]\n",
    "\n",
    "        # Normalize the number of carbon\n",
    "        excarbon = model['excarbon'][: , idx[0]]\n",
    "        for x in range (len (idx[0 , :])):\n",
    "            if excarbon[: , x]==0:\n",
    "                excarbon[: , x] = 1\n",
    "        exp_tmp = []\n",
    "        for s in range (len (tmp)):\n",
    "            exp_tmp.append (exp[i , tmp[s]] * excarbon[: , tmp[s]])\n",
    "        sol_idx = np.transpose (sol[idx[0]])\n",
    "        sol_idx = np.array (sol_idx)\n",
    "        simulated_tmp = []\n",
    "        for t in range (len (tmp)):\n",
    "            simulated_tmp.append (\n",
    "                np.array (sol_idx)[tmp[t]] * excarbon[: , tmp[t]])  # normalize the growth rate issue by factor 10\n",
    "\n",
    "        # The expected blocked reactions\n",
    "        exp_block = np.zeros ((1 , 218))  # 218怎么替换\n",
    "        rxnblockidx_pre = np.setdiff1d (rxn2block , model['rxns'][idx[0][1]])\n",
    "        rxnblockidx = []\n",
    "        for k in range (len (model['rxns'])):\n",
    "            if model['rxns'][k] in rxnblockidx_pre:\n",
    "                rxnblockidx.append (k)\n",
    "\n",
    "        simulated_block = []\n",
    "        for t in range (len (rxnblockidx)):\n",
    "            simulated_block.append (np.array (sol)[rxnblockidx[t]] * model['excarbon'][: , rxnblockidx[t]])\n",
    "        id_zero = np.where (np.array (simulated_block)!=0)\n",
    "        exp_block = exp_block[: , id_zero[0]]\n",
    "        simulated_block = np.array (simulated_block)[id_zero[0]]\n",
    "        exp_tmp = np.array (exp_tmp)\n",
    "        # print (\"exp_tmp: \" , exp_tmp)\n",
    "        # print (\"simulated_tmp: \" , simulated_tmp)\n",
    "        # print (\"exp_block: \" , exp_block)\n",
    "        # print (\"simulated_block: \" , simulated_block)\n",
    "\n",
    "        # Calculate the RMSE\n",
    "        if constrain:\n",
    "            rmse_tmp.append (np.sqrt (mean_squared_error (np.append (exp_tmp , np.transpose (exp_block)) ,\n",
    "                                                          np.append (simulated_tmp , np.transpose (simulated_block)))))\n",
    "        else:\n",
    "            if len (exp_tmp) >= 2:\n",
    "                rmse_tmp.append (np.sqrt (mean_squared_error (exp_tmp[0:2] , np.array (simulated_tmp)[0:2])))\n",
    "            else:\n",
    "                rmse_tmp.append (np.sqrt (mean_squared_error (exp_tmp[0] , [simulated_tmp[0]])))\n",
    "        simulated[i , :] = np.transpose (np.array (sol)[idx[0]])\n",
    "        #print (rmse_tmp)\n",
    "        #print (simulated[i , :])\n",
    "    rmse = sum (rmse_tmp) / len (data[: , 0])\n",
    "    print (\"RMSE = \" + str (rmse))\n",
    "\n",
    "    # end_time = time.time ()\n",
    "    # execution_time = end_time - start_time\n",
    "    # print (\"execution time: \" , execution_time , \" seconds\")\n",
    "\n",
    "    # return rmse, exp, simulated\n",
    "    return rmse , exp , simulated\n",
    "\n",
    "def abc_python_max(model , model_cobra , enzymedata , kcat_random_all , tot_prot_weight , growthdata , max_growth ,\n",
    "                   proc , sample_generation , j , rxn2block , num):\n",
    "    nstep = sample_generation / proc\n",
    "    nstep = int (nstep)\n",
    "    rmse_final = np.zeros ((1 , nstep))\n",
    "    kcat_sample = kcat_random_all[: , ((j - 1) * nstep):(j * nstep)]\n",
    "\n",
    "    # get carbonnum for each exchange rxn to further calculation of error\n",
    "    if len (model[\"excarbon\"])==0:  ##检查model中是否有excarbon, ~is_field\n",
    "        model = addCarbonNum (model)  ##补写function\n",
    "    for k in range (nstep):\n",
    "        print ('nstep:' + str (k + 1) + '/' + str (nstep))\n",
    "        kcat_random = kcat_sample[: , k]\n",
    "        #prot_cost_info_value = [enzymedata[\"MW\"][i] / kcat_random[i] for i in range (len (kcat_random))]\n",
    "        #prot_cost_info_id = enzymedata[\"rxn_list\"]\n",
    "        prot_cost_info_value = [enzymedata[\"MW\"][i] / kcat_random[i] for i in range (len (kcat_random))]\n",
    "        prot_cost_info_value = [item[0] for item in prot_cost_info_value]\n",
    "        prot_cost_info_id = [str(item[0][0]) for item in enzymedata[\"rxn_list\"]]\n",
    "        prot_cost_info = dict (zip (prot_cost_info_id , prot_cost_info_value))\n",
    "\n",
    "\n",
    "        # first search with substrate constrain\n",
    "        objective = 'r_2111'\n",
    "        osenseStr = 'max'\n",
    "        start_time = time.time ()\n",
    "\n",
    "        if len (growthdata)!=0:\n",
    "            rmse_1 , exp_1 , simulated_1 = rmsecal (model , model_cobra , growthdata , True , objective , osenseStr ,\n",
    "                                                    prot_cost_info_id , prot_cost_info_value ,prot_cost_info, tot_prot_weight ,\n",
    "                                                    rxn2block)\n",
    "        else:\n",
    "            rmse_1 = []\n",
    "            exp_1 = []\n",
    "            simulated_1 = []\n",
    "        # print(\"RMSE_1 finish !\")\n",
    "        # second searcch for maxmial growth rate without constrain\n",
    "        if len (max_growth)!=0:\n",
    "            rmse_2 , exp_2 , simulated_2 = rmsecal (model , model_cobra , max_growth , False , objective , osenseStr ,\n",
    "                                                    prot_cost_info_id , prot_cost_info_value ,prot_cost_info, tot_prot_weight ,\n",
    "                                                    rxn2block)\n",
    "        else:\n",
    "            rmse_2 = []\n",
    "            exp_2 = []\n",
    "            simulated_2 = []\n",
    "        end_time = time.time ()\n",
    "        execution_time = end_time - start_time\n",
    "        print (\"execution time: \" , execution_time , \" seconds\")\n",
    "\n",
    "        # print(\"RMSE_2 finish !\")\n",
    "\n",
    "        exp = np.array ([exp_1 , exp_2])\n",
    "        simulated = np.array ([simulated_1 , simulated_2])\n",
    "        rmse = np.array ([rmse_1 , rmse_2])\n",
    "        rmse_final[0 , k] = np.nanmean (rmse , 0)\n",
    "\n",
    "        # only output simulated result for one generation\n",
    "        if nstep!=1 or sample_generation!=1:\n",
    "            simulated = []\n",
    "            exp = []\n",
    "        print (\"rmse_final is \" , rmse_final)\n",
    "\n",
    "    return rmse_final , exp , simulated\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}